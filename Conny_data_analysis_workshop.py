# -*- coding: utf-8 -*-
"""Copy of data_analysis_workshop.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J_OeN6dwO3EDdZKUUR8IMHKAZwD1R6JH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""# 1. Learn about your data

Look at a description or data dictionary if avaialable to familiarize yourself, knowing where your data comes from, how it was collected and what it is ACTUALLY measuring is very important

https://www.kaggle.com/datasets/sahirmaharajj/employee-salaries-analysis
"""

from google.colab import files

uploaded_1 = files.upload()
uploaded_2 = files.upload()

import pandas as pd
income_data = pd.read_csv('Modified_FL_income.csv')
nri_data = pd.read_csv('NRI_Table_CensusTracts_FL_short.csv')

# 使用字符串切片方法提取'US'后面的数字
income_data['geography'] = income_data['geography'].str.split('US').str[1]
income_data['geography'] = income_data['geography'].astype(int)
# 保存更改后的DataFrame
income_data.to_csv('Modified_FL_income_cleaned.csv', index=False)

income_data['families_median_income'] = pd.to_numeric(income_data['families_median_income'], errors='coerce')
# 把str改成int

nri_data.reset_index(inplace=True)
income_data.reset_index(inplace=True)

# 假设数据集中包含了每个county的名称、收入数据和脆弱性评分
# 确定低收入阈值
income_data['low_income_threshold'] = income_data.groupby('county')['families_median_income'].transform(lambda x: x.quantile(0.05))

print(income_data[['county', 'families_median_income', 'low_income_threshold']].head())

nri_data['geography'] = nri_data['geography'].str.extract(r'T(\d+)').astype(int)

nri_data.to_csv('NRI_Table_CensusTracts_FL_short.csv', index=False)

nri_data

merged_data = pd.merge(nri_data, income_data, on='geography')



# 计算每个county低收入人群的数量（这需要你知道每个county的总人口数据）
# 假设nri_data包含了一个名为'Total_Population'的字段
merged_data['low_income_population'] = merged_data['families_number'] * 0.1

merged_data

merged_data['SOVI_SCORE']

vulnerability_score_90th_percentile = merged_data['SOVI_SCORE'].quantile(0.9)

high_risk_counties = merged_data[merged_data['SOVI_SCORE'] >= vulnerability_score_90th_percentile]

# 您可以进一步结合低收入人群数量（如果您有这个数据）来排序和选择
# high_risk_counties = high_risk_counties.sort_values(by=['Vulnerability_Score', 'low_income_population'], ascending=[False, False])

# 打印出选择的counties
print(high_risk_counties[['geography', 'SOVI_SCORE']])

low_income_counties = merged_data[merged_data['families_median_income'] <= merged_data['low_income_threshold']]
print(high_risk_counties[['geography', 'families_median_income']])

# 现在有low income 和 high risk了 找共同的
high_risk_counties['geography'] = high_risk_counties['geography'].astype(str)
low_income_counties['geography'] = low_income_counties['geography'].astype(str)

# Perform an inner join to find common 'geography' values
common_counties = pd.merge(high_risk_counties, low_income_counties, on='geography', how='inner')

# Now 'common_counties' will contain only the rows where 'geography' is present in both high-risk and low-income datasets
print(common_counties[['geography']])

common_counties['geography'] = common_counties['geography'].astype(int)

merged_data['geography'] = merged_data['geography'].astype(int)

# Filter the 'merged_data' DataFrame for the common 'geography' values
common_data = merged_data[merged_data['geography'].isin(common_counties['geography'])]

# Select the specified columns
common_data_subset = common_data[['geography', 'county', 'families_median_income', 'low_income_population']]

# Print the DataFrame with the information for the common geographies
print(common_data_subset)

common_data_subset.to_csv('common_data_subset.csv', index=False)

from google.colab import files
files.download('common_data_subset.csv')

