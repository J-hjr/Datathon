# -*- coding: utf-8 -*-
"""Datathon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kRg9UNIKUUTOyj3F7o6Dwq5-yZVAVw8R

##Census Dataset:

### `FL_income.csv`

This dataset contains demographic and economic data for different geographic areas in Florida, typically including the following fields:

1. `GEO_ID`: The geographic identifier for the census tract.
2. `NAME`: The name of the geographic area, usually the census tract name followed by the county and state.
3. `S1903_C01_015E`: The estimated number of families in the area.
4. `S1903_C01_015M`: The margin of error for the estimated number of families.
5. `S1903_C02_015E`: The estimated percentage distribution of families.
6. `S1903_C02_015M`: The margin of error for the estimated percentage distribution of families.
7. `S1903_C03_015E`: The estimated median income of families.
8. `S1903_C03_015M`: The margin of error for the estimated median income of families.

### `FL_income.csv`

This dataset provides socio-economic data for different geographic areas in Florida, typically including the following fields:

1. `GEO_ID`: A unique identifier for each census area.
2. `NAME`: Detailed name of the geographic area, usually including the census area followed by the county and state name.
3. `S1903_C01_015E`: Estimated total number of families.
4. `S1903_C01_015M`: Margin of error for the estimated total number of families.
5. `S1903_C02_015E`: Estimated percentage of families.
6. `S1903_C02_015M`: Margin of error for the estimated percentage of families.
7. `S1903_C03_015E`: Estimated median income for families in the area.
8. `S1903_C03_015M`: Margin of error for the estimated median income.

This dataset is crucial for analyzing the family composition and income levels across different geographic areas in Georgia.

### `FL_housing.csv`

This dataset contains housing data for different geographic areas in Florida, typically including the following fields:

1. `GEO_ID`: Unique identifier for the geographic area.
2. `NAME`: Name of the geographic area, typically including the census area and state name.
3. `DP04_0001E`: Total number of housing units.
4. `DP04_0001M`: Margin of error for the total number of housing units.
5. `DP04_0002E`: Number of occupied housing units.
6. `DP04_0002M`: Margin of error for the number of occupied housing units.
7. `DP04_0003E`: Number of vacant housing units.
8. `DP04_0003M`: Margin of error for the number of vacant housing units.
9. `DP04_0004E`: Homeowner vacancy rate.
10. `DP04_0004M`: Margin of error for the homeowner vacancy rate.
11. `DP04_0005E`: Rental vacancy rate.

This dataset provides detailed information on housing conditions, including total housing units, numbers of occupied and vacant units, as well as homeowner and rental vacancy rates. These details are valuable for understanding housing market conditions and planning related services.

### `FL_fin.csv`

This dataset contains data on housing occupancy and related costs for different geographic areas in Florida, typically including the following fields:

1. `GEO_ID`: Unique identifier for the geographic area.
2. `NAME`: Name of the geographic area, typically including the census area and state name.
3. `S2503_C01_001E`: Number of occupied housing units.
4. `S2503_C01_001M`: Margin of error for the number of occupied housing units.
5. `S2503_C01_024E`: Median monthly cost for occupied housing units.
6. `S2503_C01_024M`: Margin of error for the median monthly cost of occupied housing units.
7. `S2503_C02_001E`: Percentage of occupied units.
8. `S2503_C02_001M`: Margin of error for the percentage of occupied units.
9. `S2503_C03_001E`: Number of owner-occupied units.
10. `S2503_C03_001M`: Margin of error for the number of owner-occupied units.
11. `S2503_C03_024E`: Median monthly cost for owner-occupied units.
12. `S2503_C03_024M`: Margin of error for the median monthly cost of owner-occupied units.
13. `S2503_C04_001E`: Percentage of owner-occupied units.
14. `S2503_C04_001M`: Margin of error for the percentage of owner-occupied units.
15. `S2503_C04_024E`: Percentage of the median monthly cost for owner-occupied units.
16. `S2503_C04_024M`: Margin of error for the percentage of the median monthly cost of owner-occupied units.
17. `S2503_C05_001E`: Number of renter-occupied units.
18. `S2503_C05_001M`: Margin of error for the number of renter-occupied units.
19. `S2503_C05_023E`: Number of units rented without cash rent.
20. `S2503_C05_023M`: Margin of error for the number of units rented without cash rent.
21. `S2503_C05_024E`: Median monthly cost for renter-occupied units.
22. `S2503_C05_024M`: Margin of error for the median monthly cost of renter-occupied units.
23. `S2503_C06_001E`: Percentage of renter-occupied units.
24. `S2503_C06_001M`: Margin of error for the percentage of renter-occupied units.
25. `S2503_C06_024E`: Percentage of the median monthly cost for renter-occupied units.
26. `S2503_C06_024M`: Margin of error for the percentage of the median monthly cost of renter-occupied units.

These data provide detailed insights into the housing occupancy and associated costs across different geographic areas in Florida, including overall housing occupancy as well as differentiated data for owner and renter-occupied units.

### `FL_pov.csv`

This dataset contains data on the economic conditions of families and individuals in different geographic areas in Florida, typically including the following fields:

1. `GEO_ID`: Unique identifier for the geographic area.
2. `NAME`: Name of the geographic area, typically including the census area and state name.
3. `S1702_C01_001E`: Total number of families.
4. `S1702_C01_001M`: Margin of error for the total number of families.
5. `S1702_C01_017E`: Number of family heads aged 65 and above.
6. `S1702_C01_017M`: Margin of error for the number of family heads aged 65 and above.
7. `S1702_C01_018E`: Number of families receiving social security or public assistance.
8. `S1702_C01_018M`: Margin of error for the number of families receiving social security or public assistance.
9. `S1702_C01_032E`: Number of two-person families.
10. `S1702_C01_032M`: Margin of error for the number of two-person families.
11. `S1702_C01_033E`: Number of three or four-person families.
12. `S1702_C01_033M`: Margin of error for the number of three or four-person families.
13. `S1702_C01_034E`: Number of five or six-person families.
14. `S1702_C01_034M`: Margin of error for the number of five or six-person families.
15. `S1702_C01_035E`: Number of families with seven or more persons.
16. `S1702_C01_035M`: Margin of error for the number of families with seven or more persons.
17. `S1702_C01_041E`: Number of owned housing units.
18. `S1702_C01_041M`: Margin of error for the number of owned housing units.
19. `S1702_C01_042E`: Number of rented housing units.
20. `S1702_C01_042M`: Margin of error for the number of rented housing units.
21. `S1702_C02_001E`: Percentage below poverty level.
22. `S1702_C02_001M`: Margin of error for the percentage below poverty level.
23. `S1702_C02_041E`: Percentage below poverty level in owned housing units.
24. `S1702_C02_041M`: Margin of error for the percentage below poverty level in owned housing units.
25. `S1702_C02_042E`: Percentage below poverty level in rented housing units.
26. `S1702_C02_042M`: Margin of error for the percentage below poverty level in rented housing units.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

from google.colab import drive

# 连接到Google Drive
drive.mount('/content/drive')

# Importing data

# FL
FL_income = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/income/FL_income.csv')

FL_housing = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/housing/FL_housing.csv')

FL_pov = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/poverty/FL_pov.csv')

FL_fin = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/financial/FL_fin.csv')

FL_Risk = pd.read_csv('/content/drive/MyDrive/easier_challenge/risk_index/NRI_Table_CensusTracts_FL_short.csv')

# GA
GA_income = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/income/GA_income.csv')

GA_housing = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/housing/GA_housing.csv')

GA_pov = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/poverty/GA_pov.csv')

GA_fin = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/financial/GA_fin.csv')

# TX
TX_income = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/income/TX_income.csv')

TX_housing = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/housing/TX_housing.csv')

TX_pov = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/poverty/TX_pov.csv')

TX_fin = pd.read_csv('/content/drive/MyDrive/easier_challenge/census/financial/TX_fin.csv')

"""## Locating Low Income Population

The factors we eventually decided

1. `Geography`
2. `county`
3. `families_median_income`
4. `all_families'families_received_social_security`
5. `total_housing_units`
6. `occupied_housing_units`
7. `vacant_housing_units`


### Normalizing values

In order to normalize value, we use the Z-score formula to complete the tasks

$$ Z = \frac{(X - \mu)}{\sigma} $$

## Florida Section
"""

# Exact County Name from 'geographic_area_name'
FL_income['county'] = FL_income['geographic_area_name'].apply(lambda x: x.split(';')[1].strip())
FL_pov['county'] = FL_income['geographic_area_name'].apply(lambda x: x.split(';')[1].strip())
FL_fin['county'] = FL_income['geographic_area_name'].apply(lambda x: x.split(';')[1].strip())
FL_housing['county'] = FL_income['geographic_area_name'].apply(lambda x: x.split(';')[1].strip())

# Replace non-numeric income data with NaN
FL_income['families_median_income'] = pd.to_numeric(FL_income['families_median_income'], errors='coerce')

# Calculating families median income group by county
county_income_means = FL_income.groupby('county')['families_median_income'].mean()
FL_income_cleaned = FL_income.dropna(subset=['families_median_income'])

FL_income_cleaned.head()

"""We normalize families_median_income with `Z-score`"""

# We normalize the data with Z-score
FL_income_z_score = FL_income_cleaned.copy()
mean_value = FL_income_z_score['families_median_income'].mean()
std_dev = FL_income_z_score['families_median_income'].std()
FL_income_z_score['z_score_income'] = (FL_income_z_score['families_median_income'] - mean_value) / std_dev
FL_income_z_score[['county', 'families_median_income', 'z_score_income']]

# 设置绘图风格
sns.set(style="whitegrid")

# 创建箱线图
plt.figure(figsize=(10, 6))
sns.boxplot(x=FL_income_z_score['z_score_income'])

# 设置标题和标签
plt.title('Boxplot of Z-Score Normalized Families Median Income')
plt.xlabel('Z-Score of Families Median Income')

# 显示图形
plt.show()

"""将all_families进行normalized并画正态分布图"""

# Z score normalize POV

# Copy original dataset
FL_pov_z_score = FL_pov.copy()

# Mean and Std Calculation
mean_all_families = FL_pov_z_score['all_families'].mean()
std_all_families = FL_pov_z_score['all_families'].std()

# Calculating Z score
FL_pov_z_score['z_score_all_families']= (FL_pov_z_score['all_families'] - mean_all_families) / std_all_families

FL_pov_z_score[['county','all_families','z_score_all_families']].head()

# Plotting the distribution of 'z_score_all_families'
plt.figure(figsize=(10, 6))
sns.histplot(FL_pov_z_score['z_score_all_families'], kde=True, stat="density", linewidth=0)

# Adding a line for mean
plt.axvline(x=FL_pov_z_score['z_score_all_families'].mean(), color='r', linestyle='--', label='Mean')

# Adding a line for median
plt.axvline(x=FL_pov_z_score['z_score_all_families'].median(), color='g', linestyle='-', label='Median')

# Set title and labels
plt.title('Normal Distribution of Z-Score Normalized All Families')
plt.xlabel('Z-Score of All Families')
plt.ylabel('Density')
plt.legend()

# Display the plot
plt.show()

# families_received_social_security

# Mean and Std Calculation
mean_all_families_received_social_security = FL_pov_z_score['families_received_social_security'].mean()
std_all_families_received_social_security = FL_pov_z_score['families_received_social_security'].std()

# Calculating Z score
FL_pov_z_score['z_score_families_received_social_security']= (FL_pov_z_score['families_received_social_security'] - mean_all_families_received_social_security) / std_all_families_received_social_security

FL_pov_z_score[['county','families_received_social_security','z_score_families_received_social_security']].head()

# Plotting the distribution of 'z_score_families_received_social_security'
plt.figure(figsize=(10, 6))
sns.histplot(FL_pov_z_score['z_score_families_received_social_security'], kde=True, stat="density", linewidth=0)

# Adding a line for mean
plt.axvline(x=FL_pov_z_score['z_score_families_received_social_security'].mean(), color='r', linestyle='--', label='Mean')

# Adding a line for median
plt.axvline(x=FL_pov_z_score['z_score_families_received_social_security'].median(), color='g', linestyle='-', label='Median')

# Set title and labels
plt.title('Normal Distribution of Z-Score for Families Receiving Social Security')
plt.xlabel('Z-Score of Families Receiving Social Security')
plt.ylabel('Density')
plt.legend()

# Display the plot
plt.show()

# Normalizing Housing data

# Copy original dataset
FL_housing_z_score = FL_housing.copy()

# Mean and Std Calculation
mean_total_housing_units = FL_housing_z_score['total_housing_units'].mean()
std_total_housing_units = FL_housing_z_score['total_housing_units'].std()

# Calculating Z score
FL_housing_z_score['z_score_total_housing_units']= (FL_housing_z_score['total_housing_units'] - mean_total_housing_units) / std_total_housing_units

FL_housing_z_score[['county','total_housing_units','z_score_total_housing_units']].head()

# Plotting the distribution of 'z_score_total_housing_units' using the corrected column name
plt.figure(figsize=(10, 6))
sns.histplot(FL_housing_z_score['z_score_total_housing_units'], kde=True, stat="density", linewidth=0)

# Adding a line for mean
plt.axvline(x=FL_housing_z_score['z_score_total_housing_units'].mean(), color='r', linestyle='--', label='Mean')

# Adding a line for median
plt.axvline(x=FL_housing_z_score['z_score_total_housing_units'].median(), color='g', linestyle='-', label='Median')

# Set title and labels
plt.title('Normal Distribution of Z-Score Normalized Total Housing Units')
plt.xlabel('Z-Score of Total Housing Units')
plt.ylabel('Density')
plt.legend()

# Display the plot
plt.show()

# occupied_housing_units

# Mean and Std Calculation
mean_occupied_housing_units = FL_housing_z_score['occupied_housing_units'].mean()
std_occupied_housing_units = FL_housing_z_score['occupied_housing_units'].std()

# Calculating Z score
FL_housing_z_score['z_score_occupied_housing_units']= (FL_housing_z_score['occupied_housing_units'] - mean_occupied_housing_units) / std_occupied_housing_units

FL_housing_z_score[['county','occupied_housing_units','z_score_occupied_housing_units']].head()

# 设置图形样式
sns.set(style="whitegrid")

# 绘制正态分布图
plt.figure(figsize=(10, 6))
sns.histplot(FL_housing_z_score['z_score_occupied_housing_units'], kde=True, stat="density", linewidth=0)

# 添加均值和中位数线
plt.axvline(x=FL_housing_z_score['z_score_occupied_housing_units'].mean(), color='r', linestyle='--', label='Mean')
plt.axvline(x=FL_housing_z_score['z_score_occupied_housing_units'].median(), color='g', linestyle='-', label='Median')

# 设置标题和标签
plt.title('Normal Distribution of Z-Score Normalized Occupied Housing Units')
plt.xlabel('Z-Score of Occupied Housing Units')
plt.ylabel('Density')
plt.legend()

# 显示图形
plt.show()

# vacant_housing_units

# Mean and Std Calculation
mean_vacant_housing_units = FL_housing_z_score['vacant_housing_units'].mean()
std_vacant_housing_units = FL_housing_z_score['vacant_housing_units'].std()

# Calculating Z score
FL_housing_z_score['z_score_vacant_housing_units']= (FL_housing_z_score['vacant_housing_units'] - mean_vacant_housing_units) / std_vacant_housing_units

FL_housing_z_score[['county','vacant_housing_units','z_score_vacant_housing_units']].head()

# Plotting the distribution of 'z_score_vacant_housing_units'
plt.figure(figsize=(10, 6))
sns.histplot(FL_housing_z_score['z_score_vacant_housing_units'], kde=True, stat="density", linewidth=0)

# Adding a line for mean
plt.axvline(x=FL_housing_z_score['z_score_vacant_housing_units'].mean(), color='r', linestyle='--', label='Mean')

# Adding a line for median
plt.axvline(x=FL_housing_z_score['z_score_vacant_housing_units'].median(), color='g', linestyle='-', label='Median')

# Set title and labels
plt.title('Normal Distribution of Z-Score Normalized Vacant Housing Units')
plt.xlabel('Z-Score of Vacant Housing Units')
plt.ylabel('Density')
plt.legend()

# Display the plot
plt.show()

# Combining data
selected_columns_df1 = FL_income_z_score[['geography', 'county', 'families_median_income', 'z_score_income']]
selected_columns_df2 = FL_pov_z_score[['geography', 'all_families', 'z_score_all_families',
                                       'families_received_social_security', 'z_score_families_received_social_security']]
selected_columns_df3 = FL_housing_z_score[['geography', 'total_housing_units', 'z_score_total_housing_units',
                                           'occupied_housing_units', 'z_score_occupied_housing_units',
                                           'vacant_housing_units', 'z_score_vacant_housing_units']]
# Creating new dataframe to download
combined_df = selected_columns_df1.merge(selected_columns_df2, on='geography', how='inner')
combined_df = combined_df.merge(selected_columns_df3, on='geography', how='inner')

# Filter records where the Z-score of median household income is less than -1.5
low_income_areas = combined_df[combined_df['z_score_income'] < -1.5]

combined_df.to_csv('Normalized_census_data.csv')
low_income_areas.to_csv('Estimated_low_income_areas.csv')

# Download CSV
#from google.colab import files
#.download('Normalized_census_data.csv')
#files.download('Estimated_low_income_areas.csv')

low_income_areas

"""Try to use clustering"""

# Selecting relevant z-score columns for clustering
z_score_columns = [
    'z_score_income', 'z_score_all_families', 'z_score_families_received_social_security',
    'z_score_total_housing_units', 'z_score_occupied_housing_units', 'z_score_vacant_housing_units'
]

# Extracting the z-score data for clustering
cluster_input = combined_df[z_score_columns]

# Using the Elbow Method to determine the optimal number of clusters
inertia_z_scores = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=0)
    kmeans.fit(cluster_input)
    inertia_z_scores.append(kmeans.inertia_)

# Plotting the elbow curve
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), inertia_z_scores, marker='o')
plt.title('Elbow Method For Optimal k (Using Z-Scores)')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.grid(True)
plt.show()

# Assuming the optimal number of clusters is 4 based on the elbow plot
optimal_clusters = 4
kmeans = KMeans(n_clusters=optimal_clusters, random_state=0)
combined_df['Cluster'] = kmeans.fit_predict(cluster_input)

# Now your DataFrame has a new column 'Cluster' with cluster labels
combined_df.head()  # To display the first few entries with cluster labels

from sklearn.decomposition import PCA

# 运行 PCA 以减少到二维空间进行可视化
pca = PCA(n_components=2)
principal_components = pca.fit_transform(cluster_input)

# 将主成分转换为DataFrame
pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])

# 将聚类标签合并到PCA DataFrame中
pca_df = pd.concat([pca_df, combined_df['Cluster']], axis=1)

# 可视化不同聚类
fig, ax = plt.subplots(figsize=(10, 8))
colors = {0: 'red', 1: 'green', 2: 'blue', 3: 'yellow'}
for cluster in pca_df['Cluster'].unique():
    indices = pca_df['Cluster'] == cluster
    ax.scatter(pca_df.loc[indices, 'PC1'], pca_df.loc[indices, 'PC2'],
               c=colors[cluster], label=f'Cluster {cluster}', edgecolor='w', s=50)
ax.legend()
ax.grid(True)
ax.set_xlabel('Principal Component 1')
ax.set_ylabel('Principal Component 2')
ax.set_title('2D PCA Clustering Visualization')
plt.show()

# 运行 PCA 以减少到三维空间进行可视化
pca_3d = PCA(n_components=3)
principal_components_3d = pca_3d.fit_transform(cluster_input)

# 将主成分转换为DataFrame
pca_df_3d = pd.DataFrame(data=principal_components_3d, columns=['PC1', 'PC2', 'PC3'])

# 将聚类标签合并到PCA DataFrame中
pca_df_3d = pd.concat([pca_df_3d, combined_df['Cluster']], axis=1)

# 可视化不同聚类
fig_3d = plt.figure(figsize=(10, 8))
ax_3d = fig_3d.add_subplot(111, projection='3d')

colors = {0: 'red', 1: 'green', 2: 'blue', 3: 'yellow'}
for cluster in pca_df_3d['Cluster'].unique():
    indices = pca_df_3d['Cluster'] == cluster
    ax_3d.scatter(pca_df_3d.loc[indices, 'PC1'], pca_df_3d.loc[indices, 'PC2'], pca_df_3d.loc[indices, 'PC3'],
                  c=colors[cluster], label=f'Cluster {cluster}', edgecolor='w', s=50)

ax_3d.legend()
ax_3d.grid(True)
ax_3d.set_xlabel('Principal Component 1')
ax_3d.set_ylabel('Principal Component 2')
ax_3d.set_zlabel('Principal Component 3')
ax_3d.set_title('3D PCA Clustering Visualization')
plt.show()

pca = PCA(n_components=3)  # or however many components you wish to keep
principal_components = pca.fit_transform(cluster_input)

# 主成分的加载分数(loadings)
loadings = pca.components_.T * np.sqrt(pca.explained_variance_)

# 展示每个主成分和原始特征的关系
for i, component in enumerate(loadings):
    print(f"Principal Component {i+1}:")
    for j, loading in enumerate(component):
        print(f"  Feature {z_score_columns[j]}: {loading:.4f}")

"""导出用于clustering的数据"""

combined_df.to_csv('clustering_data.csv')
#files.download('clustering_data.csv')

"""## Georgia Section"""

# Exact County Name from 'geographic_area_name'
GA_income['county'] = GA_income['geographic_area_name'].apply(lambda x: x.split(';')[1].strip())
GA_pov['county'] = GA_income['geographic_area_name'].apply(lambda x: x.split(';')[1].strip())
GA_fin['county'] = GA_income['geographic_area_name'].apply(lambda x: x.split(';')[1].strip())
GA_housing['county'] = GA_income['geographic_area_name'].apply(lambda x: x.split(';')[1].strip())

# Replace non-numeric income data with NaN
GA_income['families_median_income'] = pd.to_numeric(GA_income['families_median_income'], errors='coerce')

# Calculating families median income group by county
county_income_means = GA_income.groupby('county')['families_median_income'].mean()
GA_income_cleaned = GA_income.dropna(subset=['families_median_income'])

GA_income_cleaned

# We normalize the data with Z-score
GA_income_z_score = GA_income_cleaned.copy()
mean_value = GA_income_z_score['families_median_income'].mean()
std_dev = GA_income_z_score['families_median_income'].std()
GA_income_z_score['z_score_income'] = (GA_income_z_score['families_median_income'] - mean_value) / std_dev
GA_income_z_score[['county', 'families_median_income', 'z_score_income']]

# Z score normalize POV

# Copy original dataset
GA_pov_z_score = GA_pov.copy()

# Mean and Std Calculation
mean_all_families = GA_pov_z_score['all_families'].mean()
std_all_families = GA_pov_z_score['all_families'].std()

# Calculating Z score
GA_pov_z_score['z_score_all_families']= (GA_pov_z_score['all_families'] - mean_all_families) / std_all_families

GA_pov_z_score[['county','all_families','z_score_all_families']].head()

# families_received_social_security

# Mean and Std Calculation
mean_all_families_received_social_security = GA_pov_z_score['families_received_social_security'].mean()
std_all_families_received_social_security = GA_pov_z_score['families_received_social_security'].std()

# Calculating Z score
GA_pov_z_score['z_score_families_received_social_security'] = (
    GA_pov_z_score['families_received_social_security'] - mean_all_families_received_social_security
) / std_all_families_received_social_security

GA_pov_z_score[['county', 'families_received_social_security', 'z_score_families_received_social_security']].head()

# Normalizing Housing data

# Copy original dataset
GA_housing_z_score = GA_housing.copy()

# Mean and Std Calculation
mean_total_housing_units = GA_housing_z_score['total_housing_units'].mean()
std_total_housing_units = GA_housing_z_score['total_housing_units'].std()

# Calculating Z score
GA_housing_z_score['z_score_total_housing_units'] = (
    GA_housing_z_score['total_housing_units'] - mean_total_housing_units
) / std_total_housing_units

GA_housing_z_score[['county', 'total_housing_units', 'z_score_total_housing_units']].head()

# occupied_housing_units

# Mean and Std Calculation
mean_occupied_housing_units = GA_housing_z_score['occupied_housing_units'].mean()
std_occupied_housing_units = GA_housing_z_score['occupied_housing_units'].std()

# Calculating Z score
GA_housing_z_score['z_score_occupied_housing_units'] = (
    GA_housing_z_score['occupied_housing_units'] - mean_occupied_housing_units
) / std_occupied_housing_units

GA_housing_z_score[['county', 'occupied_housing_units', 'z_score_occupied_housing_units']].head()

# vacant_housing_units

# Mean and Std Calculation
mean_vacant_housing_units = GA_housing_z_score['vacant_housing_units'].mean()
std_vacant_housing_units = GA_housing_z_score['vacant_housing_units'].std()

# Calculating Z score
GA_housing_z_score['z_score_vacant_housing_units'] = (
    GA_housing_z_score['vacant_housing_units'] - mean_vacant_housing_units
) / std_vacant_housing_units

GA_housing_z_score[['county', 'vacant_housing_units', 'z_score_vacant_housing_units']].head()

# Combining data
selected_columns_df1 = GA_income_z_score[['geography', 'county', 'families_median_income', 'z_score_income']]
selected_columns_df2 = GA_pov_z_score[['geography', 'all_families', 'z_score_all_families',
                                       'families_received_social_security', 'z_score_families_received_social_security']]
selected_columns_df3 = GA_housing_z_score[['geography', 'total_housing_units', 'z_score_total_housing_units',
                                           'occupied_housing_units', 'z_score_occupied_housing_units',
                                           'vacant_housing_units', 'z_score_vacant_housing_units']]
# Creating new dataframe to download
combined_df_GA = selected_columns_df1.merge(selected_columns_df2, on='geography', how='inner')
combined_df_GA = combined_df_GA.merge(selected_columns_df3, on='geography', how='inner')

# Filter records where the Z-score of median household income is less than -1.5
low_income_areas_GA = combined_df_GA[combined_df_GA['z_score_income'] < -1.5]

combined_df_GA.to_csv('Normalized_census_data_GA.csv')
low_income_areas_GA.to_csv('Estimated_low_income_areas_GA.csv')

# Download CSV
from google.colab import files
files.download('Normalized_census_data_GA.csv')
files.download('Estimated_low_income_areas_GA.csv')

low_income_areas_GA

"""## Plotting"""

import matplotlib.pyplot as plt

# Calculate Florida state-wide average median income again for clarity
florida_statewide_average = county_income_means.mean()

# Plotting
plt.figure(figsize=(14, 8))
county_income_means.plot(kind='bar', color='skyblue')
plt.axhline(y=florida_statewide_average, color='r', linestyle='-', label='Florida Statewide Average')
plt.xlabel('County')
plt.ylabel('Average Median Income')
plt.title('Comparison of Average Median Income by County vs. Florida Statewide Average')
plt.xticks(rotation=45)
plt.legend()
plt.tight_layout()

plt.show()

# 计算四分位数和四分位间距
quartiles = FL_income_cleaned['families_median_income'].quantile([0.25, 0.5, 0.75])
iqr = quartiles[0.75] - quartiles[0.25]

# Creating a boxplot to visualize the quartiles and outliers
plt.figure(figsize=(8, 6))
plt.boxplot(FL_income_cleaned['families_median_income'], vert=False, patch_artist=True)
plt.title('Boxplot of Family Median Incomes in Florida')
plt.xlabel('Family Median Income')
plt.grid(True)
plt.show()

county_comparison = pd.DataFrame(county_income_means)
county_comparison.rename(columns={'families_median_income': 'Avg_income_of_County'}, inplace = True)

county_comparison

# Create a new dataframe to visualize the comparison of each county against the Florida median
county_comparison['Above_Florida_Mean'] = county_income_means > florida_statewide_average

# Plotting
plt.figure(figsize=(16, 8))
county_comparison['Avg_income_of_County'].plot(kind='bar',
                                                 color=county_comparison['Above_Florida_Mean'].map({True: 'green', False: 'red'}))
plt.axhline(y=florida_statewide_average, color='black', linestyle='--', label='Florida State Mean of Median')
plt.xlabel('County')
plt.ylabel('Average Median Income')
plt.title('County Mean Income Comparison to Florida State Mean')
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()

plt.show()

"""下面我们将通过对比每个地区和Florida Mean of Median的数据去尝试分类成高于平均值的地区和低于平均值的地区，并按照County分类

"""

import matplotlib.pyplot as plt

# Median compares to Median of the Whole States

# 计算佛罗里达州的家庭中位收入中位数
florida_median_income = FL_income['families_median_income'].median()

# 创建一个新的 DataFrame 来对比每个县内的地区是否超过佛罗里达州的中位数
FL_income['Above_Florida_Median'] = FL_income['families_median_income'] > florida_median_income
# 对每个县进行分组，并计算超过和未超过州中位收入的地区数
county_above_below_median = FL_income.groupby('county')['Above_Florida_Median'].value_counts().unstack(fill_value=0)
county_above_below_median.columns = ['Not_Above_Florida_Median', 'Above_Florida_Median']

# 绘制柱状图
fig, ax = plt.subplots(figsize=(16, 8))

# 将数据分成两组以便绘制两个柱状图
width = 0.35  # 柱子的宽度
indices = range(len(county_above_below_median))  # x轴的位置数组

ax.bar(indices, county_above_below_median['Above_Florida_Median'], width, label='Above Florida Median', color='green')
ax.bar([i + width for i in indices], county_above_below_median['Not_Above_Florida_Median'], width, label='Not Above Florida Median', color='red')

ax.axhline(y=0, color='black')  # 添加 y=0 的参考线
ax.set_xlabel('County')
ax.set_ylabel('Number of Tracts')
ax.set_title('Number of Tracts Above and Below Florida State Median Income by County')
ax.set_xticks([i + width/2 for i in indices])  # 设置x轴标签的位置在两个柱状图的中间
ax.set_xticklabels(county_above_below_median.index, rotation=90)  # 设置x轴标签
ax.legend(title='Median Income', bbox_to_anchor=(1.05, 1), loc='upper left')

plt.tight_layout()  # 适应紧凑的布局
plt.show()

"""下面的图我们将分析低于平均值的地区，在他们的county出现的频率，从而来判断哪些地区Low income的水平占总体的比较多"""

county_above_below_median

# 计算每个县低于佛罗里达州中位数的比率
county_above_below_median['Below_Median_Ratio'] = county_above_below_median['Not_Above_Florida_Median'] / (county_above_below_median['Above_Florida_Median'] + county_above_below_median['Not_Above_Florida_Median'])

# 绘制面积图
plt.figure(figsize=(16, 8))
county_above_below_median['Below_Median_Ratio'].plot(kind='area', alpha=0.5, color='purple')  # alpha 设置透明度，增加视觉效果
plt.xlabel('County')
plt.ylabel('Ratio of Tracts Below Median')
plt.title('Area Plot of Tracts Below Florida State Median Income by County')
plt.xticks(rotation=90)
plt.tight_layout()  # 适应紧凑的布局

plt.show()

# 这个热力图不知道为什么很奇怪，正常来说是斜对角应该1:1？

# 假设我们有一个近似方形的布局，你可以根据县的实际数量调整
num_counties = len(county_above_below_median['Below_Median_Ratio'])
side_length = int(np.sqrt(num_counties))  # 估计边长
heatmap_data = county_above_below_median['Below_Median_Ratio'].values[:side_length**2].reshape((side_length, side_length))

# 绘制热力图
plt.figure(figsize=(10, 8))
sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', fmt=".2f", cbar_kws={'label': 'Ratio of Tracts Below Median'})
plt.title('Heatmap of Tracts Below Florida State Median Income by County')
plt.xlabel('County Index')
plt.ylabel('County Index')
plt.show()

